{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TripAdvisor Recomender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Collection from TripAdvisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data are scraped using Selenium and BeautifulSoup from TripAdvisor website from late April to early May 2019. The hotels are from 16 popular European tourist destination cities and their TripAdvisor rating range from 3.0 to 5.0. The collected data are separated into 4 files. These files are:\n",
    "\n",
    "1) tripadvisor_data.csv (hotel information from the hotel listings from the city section)\n",
    "\n",
    "2) tripadvisor_hotel.txt (hotel information from the hotel details webpage in json format)\n",
    "\n",
    "3) tripadvisor_reviewer.csv (brief reviewer information from the hotel details webpage)\n",
    "\n",
    "4) tripadvisor_hotel_review.csv (reviews written by reviewer from the TripAdvisor reviewer webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup \n",
    "import urllib\n",
    "import requests, re\n",
    "from datetime import datetime\n",
    "import time as t\n",
    "from time import time\n",
    "import os, sys\n",
    "from lxml import html, etree\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping through TripAdvisor City Section for Hotel Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_hotel_list(locality, checkin_date, checkout_date, hotel_data, sort=\"popularity\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    locality is the city location of the hotel search\n",
    "    \n",
    "    checkin_date and checkout_date are the start and end date of hotel stay.\n",
    "    It should be year/month/day string format, ie. '2019/07/01'\n",
    "    \n",
    "    sort is the method of how search results are displayed either by order of 'popularity', 'value', 'price' or 'distance'\n",
    "    \n",
    "    hotel_data is a list used to collect scraped hotel information\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    check_in = checkin_date\n",
    "    check_out = checkout_date\n",
    "    \n",
    "    geo_url = 'https://www.tripadvisor.com/TypeAheadJson?action=API&startTime='+str(int(time()))+'&uiOrigin=GEOSCOPE&source=GEOSCOPE&interleaved=true&types=geo,theme_park&neighborhood_geos=true&link_type=hotel&details=true&max=12&injectNeighborhoods=true&query='+locality\n",
    "    api_response  = requests.get(geo_url, verify=False).json()\n",
    "    url_from_autocomplete = \"http://www.tripadvisor.com\"+api_response['results'][0]['url']\n",
    "    geo = api_response['results'][0]['value'] \n",
    "    date = check_in+\"_\"+check_out\n",
    "    \n",
    "    form_data = {'changeSet': 'TRAVEL_INFO',\n",
    "                'showSnippets': 'false',\n",
    "                'staydates':date,\n",
    "                'uguests': '2',\n",
    "                'sortOrder':sort\n",
    "    \n",
    "                }\n",
    "    \n",
    "    headers = {\n",
    "                'Accept': 'text/javascript, text/html, application/xml, text/xml, */*',\n",
    "                'Accept-Encoding': 'gzip,deflate',\n",
    "                'Accept-Language': 'en-US,en;q=0.5',\n",
    "                'Cache-Control': 'no-cache',\n",
    "                'Connection': 'keep-alive',\n",
    "                'Content-Type': 'application/x-www-form-urlencoded; charset=utf-8',\n",
    "                'Host': 'www.tripadvisor.com',\n",
    "                'Pragma': 'no-cache',\n",
    "                'Referer': url_from_autocomplete,\n",
    "                'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:28.0) Gecko/20100101 Firefox/28.0',\n",
    "                'X-Requested-With': 'XMLHttpRequest'\n",
    "                }\n",
    "    \n",
    "    cookies=  {\"SetCurrency\":\"USD\"}\n",
    "    page_response  = requests.post(url = url_from_autocomplete,data=form_data,headers = headers, cookies = cookies, verify=False)\n",
    "    if page_response.status_code != 200:\n",
    "        print('Page error for, '+ url_from_autocomplete +', is found.')\n",
    "        return hotel_data\n",
    "    else:\n",
    "        parser = html.fromstring(page_response.text)\n",
    "        hotel_data = iterate_hotels(parser, locality, hotel_data)\n",
    "        return hotel_data\n",
    "    \n",
    "    \n",
    "    \n",
    "def iterate_hotels(parser, locality, hotel_data):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    this function is called by process_hotel_list() in order to parse and scrape hotel information\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    next_page = parser.xpath('//a[contains(@class,\"nav next taLnk ui_button primary\")]/@href')\n",
    "    next_page = 'http://www.tripadvisor.com' + next_page[0] if next_page else  None\n",
    "    \n",
    "    hotel_lists = parser.xpath('//div[contains(@class,\"listItem\")]//div[contains(@class,\"listing collapsed\")]')\n",
    "    if not hotel_lists:\n",
    "        hotel_lists = parser.xpath('//div[contains(@class,\"listItem\")]//div[@class=\"listing \"]')\n",
    "\n",
    "    for index, hotel in enumerate(hotel_lists): # grab the element of each feature from html\n",
    "        XPATH_HOTEL_LINK = './/a[contains(@class,\"property_title\")]/@href'\n",
    "        XPATH_REVIEWS  = './/a[@class=\"review_count\"]//text()'\n",
    "        XPATH_RANK = './/div[@class=\"popRanking\"]//text()'\n",
    "        XPATH_RATING = './/a[contains(@class,\"ui_bubble_rating\")]//@alt'\n",
    "        XPATH_HOTEL_NAME = './/a[contains(@class,\"property_title\")]//text()'\n",
    "        XPATH_HOTEL_FEATURES = './/div[contains(@class,\"common_hotel_icons_list\")]//li//text()'\n",
    "        XPATH_HOTEL_PRICE = './/div[contains(@data-sizegroup,\"mini-meta-price\")]/text()'\n",
    "        XPATH_VIEW_DEALS = './/div[contains(@data-ajax-preserve,\"viewDeals\")]//text()' \n",
    "        XPATH_BOOKING_PROVIDER = './/div[contains(@data-sizegroup,\"mini-meta-provider\")]//text()'\n",
    "\n",
    "        raw_booking_provider = hotel.xpath(XPATH_BOOKING_PROVIDER)\n",
    "        raw_no_of_deals =  hotel.xpath(XPATH_VIEW_DEALS)\n",
    "        raw_hotel_link = hotel.xpath(XPATH_HOTEL_LINK)\n",
    "        raw_no_of_reviews = hotel.xpath(XPATH_REVIEWS)\n",
    "        raw_rank = hotel.xpath(XPATH_RANK)\n",
    "        raw_rating = hotel.xpath(XPATH_RATING)\n",
    "        raw_hotel_name = hotel.xpath(XPATH_HOTEL_NAME)\n",
    "        raw_hotel_features = hotel.xpath(XPATH_HOTEL_FEATURES)\n",
    "        raw_hotel_price_per_night  = hotel.xpath(XPATH_HOTEL_PRICE)\n",
    "\n",
    "        url = 'http://www.tripadvisor.com' + raw_hotel_link[0] if raw_hotel_link else  None\n",
    "        reviews = ''.join(raw_no_of_reviews).replace(\"reviews\",\"\").replace(\",\",\"\") if raw_no_of_reviews else 0 \n",
    "        rank = ''.join(raw_rank) if raw_rank else None\n",
    "        rating = ''.join(raw_rating).replace('of 5 bubbles','').strip() if raw_rating else None\n",
    "        name = ''.join(raw_hotel_name).strip() if raw_hotel_name else None\n",
    "        hotel_features = ','.join(raw_hotel_features)\n",
    "        price_per_night = ''.join(str(*raw_hotel_price_per_night)).replace('\\n','') if raw_hotel_price_per_night else None\n",
    "        no_of_deals = re.findall(\"all\\s+?(\\d+)\\s+?\",''.join(raw_no_of_deals))\n",
    "        booking_provider = ''.join(raw_booking_provider).strip() if raw_booking_provider else None\n",
    "\n",
    "        if no_of_deals:\n",
    "            no_of_deals = no_of_deals[0]\n",
    "        else:\n",
    "            no_of_deals = 0\n",
    "\n",
    "        data = {\n",
    "                'hotel_name':name,\n",
    "                'url':url,\n",
    "                'locality':locality,\n",
    "                'reviews':reviews,\n",
    "                'tripadvisor_rating':rating,\n",
    "                'hotel_features':hotel_features,\n",
    "                'price_per_night':price_per_night,\n",
    "                'no_of_deals':no_of_deals,\n",
    "                'booking_provider':booking_provider\n",
    "\n",
    "                }\n",
    "        hotel_data.append(data)\n",
    "        \n",
    "        if next_page:\n",
    "            t.sleep(1)\n",
    "        try:\n",
    "            page_response = requests.get(next_page)\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            t.sleep(60)\n",
    "            page_response = requests.get(next_page)\n",
    "            parser = html.fromstring(page_response.text)\n",
    "            hotel_data = iterate_hotels(parser, locality, hotel_data)\n",
    "        else:\n",
    "            parser = html.fromstring(page_response.text)\n",
    "            hotel_data = iterate_hotels(parser, locality, hotel_data)\n",
    "        finally:\n",
    "            return hotel_data\n",
    "        \n",
    "    return hotel_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_hotel_list('London, England', '2019/07/01', '2019/07/15', hotel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write hotel_data to a csv file called tripadvisor_data.csv\n",
    "# with open('tripadvisor_data.csv','wb')as csvfile:  # substitute 'wb' for 'ab' to append hotel_data to existing tripadvisor_data.csv\n",
    "            fieldnames = ['hotel_name','url','locality','reviews','tripadvisor_rating','price_per_night','booking_provider','no_of_deals','hotel_features']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for row in hotel_data:\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tadata = pd.read_csv('tripadvisor_data.csv')\n",
    "tadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tadata = tadata.drop_duplicates() # drop duplicate hotels from list\n",
    "# tadata.to_csv(\"tripadvisor_data.csv\", index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping through Individual TripAdvisor Hotel Webpage for Hotel Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_hotel_details(hotel_url, retry=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    hotel_url is hotel webpage at TripAdvisor\n",
    "    retry attempts to reconnect to TripAdvisor if it fails up to MAX_RETRY times\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    MAX_RETRY = 10\n",
    "    RETRY = 0\n",
    "\n",
    "    headers = {\n",
    "                \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "                \"accept-encoding\": \"gzip, deflate, br\",\n",
    "                \"accept-language\": \"en-GB,en;q=0.9,en-US;q=0.8,ml;q=0.7\",\n",
    "                \"cache-control\": \"max-age=0\",\n",
    "                \"upgrade-insecure-requests\": \"1\",\n",
    "                \"user-agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/71.0.3578.80 Chrome/71.0.3578.80 Safari/537.36\",\n",
    "                }\n",
    "\n",
    "    response = requests.get(hotel_url, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        print('error: Page not found, status_code: 404')\n",
    "        pass\n",
    "    parser = html.fromstring(response.text, myurl)\n",
    "    script_text = ' '.join(''.join(parser.xpath('//script//text()')).split())\n",
    "    raw_json = re.findall(\"define\\(\\'@ta\\/page\\-manifest\\'\\,\\[\\]\\,function\\(\\)\\{return\\s+({.*?});\\}\\);\", script_text)\n",
    "    try:\n",
    "        json_loaded = json.loads(raw_json[0])\n",
    "    except Exception as e:\n",
    "        json_loaded = {}\n",
    "        if RETRY < MAX_RETRY:\n",
    "            RETRY = RETRY+1\n",
    "            # Retrying the same URL\n",
    "            process_hotel_details(hotel_url, RETRY)\n",
    "\n",
    "    XPATH_NAME = '//h1[@id=\"HEADING\"]//text()'\n",
    "    XPATH_RANK = '//span[contains(@class,\"popularity\")]//text()'\n",
    "    XPATH_FULL_ADDRESS_JSON = '//script[@type=\"application/ld+json\"]//text()'\n",
    "\n",
    "    raw_name = parser.xpath(XPATH_NAME)\n",
    "    raw_rank = parser.xpath(XPATH_RANK)\n",
    "    raw_address_json = parser.xpath(XPATH_FULL_ADDRESS_JSON)\n",
    "    name = clean(raw_name)\n",
    "    rank = clean(raw_rank)\n",
    "    if not name:\n",
    "        if RETRY < MAX_RETRY:\n",
    "            RETRY = RETRY+1\n",
    "            # Retrying the same URL\n",
    "            process_hotel_details(hotel_url, RETRY)\n",
    "\n",
    "    hotel_rating = 0\n",
    "    review_count = 0\n",
    "    address = {}\n",
    "    if raw_address_json:\n",
    "        try:\n",
    "            parsed_address_info = json.loads(raw_address_json[0])\n",
    "            rating = parsed_address_info.get('aggregateRating', {})\n",
    "            address = parsed_address_info.get(\"address\", {})\n",
    "\n",
    "            hotel_rating = rating.get('ratingValue')\n",
    "            review_count = rating.get('reviewCount')\n",
    "\n",
    "            address = {\n",
    "                        'street_address': address.get('streetAddress'),\n",
    "                        'region': address.get('addressRegion'),\n",
    "                        'locality': address.get('addressLocality'),\n",
    "                        'country': address.get(\"addressCountry\", {}).get(\"name\"),\n",
    "                        'zipcode': address.get(\"postalCode\")\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            review_count = hotel_rating = 0\n",
    "            raise e\n",
    "\n",
    "    ratings = {}\n",
    "    elems = parser.find_class(\"hotels-review-list-parts-ReviewRatingFilter__row_num--gIW_f\")\n",
    "    if elems:\n",
    "        ratings = {\n",
    "            'Excellent': elems[0].text,\n",
    "            'Good': elems[1].text,\n",
    "            'Average': elems[2].text,\n",
    "            'Poor': elems[3].text,\n",
    "            'Terrible': elems[4].text\n",
    "                }\n",
    "\n",
    "    amenities = parser.find_class(\"hotels-hotel-review-about-with-photos-Amenity__name--2IUMR\")\n",
    "    amenity_list = []     \n",
    "    for a in amenities:\n",
    "        amenity_list.append(a.text)\n",
    "\n",
    "    data = {\n",
    "            'address': address,\n",
    "            'ratings': ratings,\n",
    "            'amenities': amenity_list,\n",
    "            'rating': float(hotel_rating) if hotel_rating else 0.0,\n",
    "            'review_count': int(review_count) if review_count else 0,\n",
    "            'name': name,\n",
    "            'rank': rank,\n",
    "            'hotel_url': hotel_url\n",
    "            }\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    processing scraped information before adding to a json formatted list of dictionaries\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if text:\n",
    "        # Removing \\n \\r and \\t\n",
    "        return ' '.join(''.join(text).split()).strip()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_details = []\n",
    "for index, hotel in enumerate(tadata['url'][0:1000]):\n",
    "    result = process_request(hotel)\n",
    "    hotel_details.append(result)\n",
    "    print(index)  # keeping track of progress in case of error\n",
    "    t.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = []\n",
    "details.extend(hotel_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving details list as tripadvisor_hotel.txt in json format\n",
    "# with open('tripadvisor_hotel.txt', 'w') as out_file:\n",
    "    json.dump(details, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting tripadvisor_hotel.txt to pandas DataFrame\n",
    "tahotel = pd.read_json('tripadvisor_hotel.txt')\n",
    "tahotel = tahotel[tahotel.review_count >= 100]   # filtering hotels with more than 100 reviews \n",
    "tahotel.index = range(len(tahotel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping through Individual TripAdvisor Hotel Webpage for Guest Review Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_reviews(hotel_url, reviewer_list):\n",
    "    \n",
    "    response = requests.get(hotel_url)\n",
    "    if response.status_code != 200:\n",
    "        print('Error is found on page, '+ hotel_url)\n",
    "        return reviewer_list\n",
    "    else:\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        reviews = soup.findAll(class_ = 'hotels-review-list-parts-SingleReview__reviewContainer--d54T4')\n",
    "        review_count = 10\n",
    "        reviewer_list = iterate_review_page(soup, reviews, review_count, reviewer_list)\n",
    "        return reviewer_list\n",
    "            \n",
    "def iterate_review_page(soup, reviews, review_count, reviewer_list):           \n",
    "\n",
    "    next_page = soup.find('a', class_=\"ui_button nav next primary \", href=True)\n",
    "    next_page = 'http://www.tripadvisor.com'+next_page['href'] if next_page['href'] else  None\n",
    "       \n",
    "    for r in reviews:\n",
    "        try:\n",
    "            contribute = r.find('span', class_ = 'social-member-MemberHeaderStats__bold--3z3qh').get_text()\n",
    "            contribute = int(contribute.replace(',', '')) \n",
    "        except AttributeError:\n",
    "            contribute = 0    \n",
    "            pass\n",
    "        \n",
    "        if contribute > 25 and review_count > 0: #filter reviewer with more than 25 reviews and a limit of 10 reviewers for each hotel\n",
    "            try:\n",
    "                reviewer = r.find('a', class_ = 'ui_header_link social-member-event-MemberEventOnObjectBlock__member--35-jC').get_text()\n",
    "            except AttributeError:\n",
    "                reviewer = \"NONE PROVIDED\"\n",
    "                \n",
    "            reviewer_website = r.find('a', href=True)\n",
    "            reviewer_website = 'http://www.tripadvisor.com'+reviewer_website['href']\n",
    "            rating = r.find('span', class_=\"ui_bubble_rating\")\n",
    "            rating = str(rating).strip('\"0></span>')[-1:]\n",
    "            try:\n",
    "                date =  r.find(class_ = 'hotels-review-list-parts-EventDate__event_date--CRXs4').find('span').get_text()\n",
    "            except:\n",
    "                date = ''\n",
    "            \n",
    "            if reviewer_website not in list(reviewer_list['user_link']): # avoid duplicate reviewer\n",
    "                \n",
    "                df = pd.DataFrame({'uid':reviewer, 'user_link':reviewer_website, 'rating':int(rating), 'date_of_stay':date[14:], 'num_of_reviews':int(contribute)}, \n",
    "                                  columns=['uid', 'user_link', 'rating', 'date_of_stay', 'num_of_reviews'], index=[0])\n",
    "                reviewer_list = pd.concat([reviewer_list, df], axis =0)   \n",
    "                review_count -= 1\n",
    "            else:\n",
    "                pass\n",
    "    if next_page and review_count > 0:\n",
    "        t.sleep(1)\n",
    "        try:\n",
    "            response = requests.get(next_page)\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            t.sleep(60) # Retrying same url after 1 minute\n",
    "            response = requests.get(next_page)\n",
    "            soup = BeautifulSoup(response.text)\n",
    "            reviews = soup.findAll(class_ = 'hotels-review-list-parts-SingleReview__reviewContainer--d54T4')\n",
    "            reviewer_list = iterate_review_page(soup, reviews, review_count, reviewer_list)\n",
    "        else:\n",
    "            soup = BeautifulSoup(response.text)\n",
    "            reviews = soup.findAll(class_ = 'hotels-review-list-parts-SingleReview__reviewContainer--d54T4')\n",
    "            reviewer_list = iterate_review_page(soup, reviews, review_count, reviewer_list)\n",
    "        finally:\n",
    "            return reviewer_list\n",
    "\n",
    "    return reviewer_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, hotel in enumerate(tahotel[0:1000]['hotel_url']):\n",
    "    hotel_url = hotel\n",
    "    print(index) # keeping track of progress in case of error\n",
    "    n = len(reviewer_list)\n",
    "    hotel_df = process_reviews(hotel_url, reviewer_list)\n",
    "    reviewer_list = pd.concat([reviewer_list, hotel_df[:][n:]], axis =0)\n",
    "    t.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_list.to_csv('tripadvisor_reviewer.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping through TripAdvisor Guest Reviewer Webpage for Hotel Reviews using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_other_reviews(user_url, hotel_review_list):\n",
    "    \n",
    "    driver.get(user_url)\n",
    "    t.sleep(1.5)\n",
    "    try: # check if driver get user_url page\n",
    "        response = driver.page_source\n",
    "        hotel_review_list = try_button(driver, response, user_url, hotel_review_list)   \n",
    "    except: # retry getting user_url with Selenium\n",
    "        driver.get(user_url)\n",
    "        t.sleep(1.5)\n",
    "        try:\n",
    "            response = driver.page_source\n",
    "        except Exception as e: # print reason for why it fails\n",
    "            print(e)\n",
    "        else: # check if 'show more' button is clickable\n",
    "            hotel_review_list = try_button(driver, response, user_url, hotel_review_list)\n",
    "            \n",
    "    return hotel_review_list\n",
    " \n",
    "\n",
    "def try_button(driver, response, user_url, hotel_review_list):   # check if 'show more' button is clickable\n",
    "    \n",
    "    try:\n",
    "        python_button = driver.find_element_by_class_name(\"social-show-more-ShowMore__button_contents--1djai\")\n",
    "        python_button.click()\n",
    "        soup = BeautifulSoup(response)\n",
    "        hotel_review_list = iterate_reviewer_page(soup, user_url, hotel_review_list)\n",
    "    except:\n",
    "        soup = BeautifulSoup(response)\n",
    "        hotel_review_list = iterate_reviewer_page(soup, user_url, hotel_review_list)\n",
    "        \n",
    "    return hotel_review_list\n",
    "\n",
    "    \n",
    "def iterate_reviewer_page(soup, user_url, hotel_review_list):    # filter out reviews that are not of hotels from the 16 european cities \n",
    "    \n",
    "    reviews = soup.findAll('div', class_ = 'social-sections-CardSection__card_section--3Hc9Y ui_card section')\n",
    "    for r in reviews:\n",
    "        hotel = r.find('div', class_=\"social-sections-POICarousel__container--297jy social-sections-POICarousel__carousel--1vz03\").find('a', href=True)\n",
    "        if not hotel:\n",
    "            continue\n",
    "        try:\n",
    "            hotel = hotel['href']    # grab website link info\n",
    "        except:\n",
    "            continue\n",
    "        if \"Hotel_Review\" in hotel:    # check if it is a hotel review and from the 16 cities\n",
    "            if 'London_England.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Paris_lle_de_France.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Rome_Lazio.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Barcelona_Catalonia.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Berlin.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Vienna.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Prague_Bohemia.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Budapest_Central_Hungary.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Athens_Attica.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Florence_Tuscany.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Milan_Lombardy.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Madrid.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Lisbon_District_Central_Portugal.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Edinburgh_Scotland.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Amsterdam_North_Holland_Province.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            elif 'Brussels.html' in hotel:\n",
    "                hotel_review_list = scrape_reviews(r, user_url, hotel_review_list, hotel)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    return hotel_review_list\n",
    "\n",
    "\n",
    "def scrape_reviews(r, user_url, hotel_review_list, hotel):\n",
    "    \n",
    "    reviewer = r.find('a', class_ = 'ui_link social-member-event-MemberEventOnObjectBlock__member--35-jC').get_text()\n",
    "    try:\n",
    "        title = r.find('div', class_=\"social-sections-ReviewSection__title--35ISZ social-sections-ReviewSection__linked--2rTun\").get_text()\n",
    "    except:\n",
    "        title = ''\n",
    "    try:\n",
    "        preview = r.find('q', class_=\"social-sections-ReviewSection__quote--3gE7d\").get_text()\n",
    "    except:\n",
    "        preview = ''\n",
    "    rating = r.find('span', class_=\"ui_bubble_rating\")\n",
    "    rating = str(rating).strip('\"0></span>')[-1:]\n",
    "    hotel = 'http://www.tripadvisor.com' + hotel\n",
    "    try:\n",
    "        date =  r.find('div', class_ = 'social-review-info-EventDate__event_date--2d3vn').find('span').get_text()\n",
    "    except:\n",
    "        date = ''\n",
    "    df = pd.DataFrame({'uid':reviewer, 'user_link':user_url, 'rating':float(rating), 'hotel_link':hotel, 'date_of_stay':date[14:], 'title':title, 'review_preview':preview}, \n",
    "                                  columns=['uid', 'user_link', 'rating', 'hotel_link', 'date_of_stay', 'title', 'review_preview'], index=[0])\n",
    "    hotel_review_list = pd.concat([hotel_review_list, df])   \n",
    "    hotel_review_list = hotel_review_list.reset_index(drop=True)\n",
    "    return hotel_review_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_review_list = pd.DataFrame(columns=['uid', 'user_link', 'rating', 'hotel_link', 'date_of_stay', 'title', 'review_preview'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument(\"--test-type\")\n",
    "driver = webdriver.Chrome(chrome_options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, user_url in enumerate(reviewer_list.user_link[0:10000]):\n",
    "    print(index)\n",
    "    hotel_review_list = process_other_reviews(user_url, hotel_review_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env]",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
